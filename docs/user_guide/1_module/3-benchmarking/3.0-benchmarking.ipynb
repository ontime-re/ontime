{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "550c22a8-085f-45f1-9af5-35896f670515",
   "metadata": {},
   "source": [
    "# Module - Benchmarking\n",
    "Ontime provides a Benchmark class that can be used to run a number of prediction models on a number of datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27e27d12-d338-47d3-8fd3-b31ff80ac57c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T06:55:56.084401800Z",
     "start_time": "2024-06-24T06:55:51.801812900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charlie/.local/lib/python3.10/site-packages/sklearn/datasets/_arff_parser.py:430: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(dtype)\n"
     ]
    }
   ],
   "source": [
    "# Import to be able to import python package from src\n",
    "import sys\n",
    "sys.path.insert(0, '../../../../src')\n",
    "\n",
    "from ontime.module.benchmarking.benchmark import Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476a848a-77d7-4efc-840f-665a7cdc1857",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "A Benchmark instance can be initialized with a list of datasets, models and metrics to run through. When invoking run(), it will train and test every dataset on every model, and compute every metric on the predicted data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30689a0a-9ed7-4eca-ab6e-6de1cb1c9e21",
   "metadata": {},
   "source": [
    "### Preparing models\n",
    "Models are wrapped in BenchmarkModelHolders that will instanciate them for each dataset.\n",
    "If a model can't be instanciated and invoked as in BenchmarkModelHolder's implementation, a child class can be written and submitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71c4bc47-8479-46f1-a4c4-7ad5478020f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T06:55:56.084401800Z",
     "start_time": "2024-06-24T06:55:56.073910600Z"
    }
   },
   "outputs": [],
   "source": [
    "from ontime.core.time_series.time_series import TimeSeries\n",
    "from typing import Any\n",
    "from darts.models import ARIMA, BATS\n",
    "\n",
    "m1 = Benchmark.BenchmarkModelHolder(ARIMA, 'ARIMA', {'p': 12, 'd': 1, 'q': 2})\n",
    "m2 = Benchmark.BenchmarkModelHolder(BATS, 'BATS', {'use_trend': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### BenchmarkModelHolder child class example\n",
    "Here we are using a Darts RNN (based on pytorch) since BenchmarkModelHolder does not currently support pytorch models by default. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3e604cdd42b3b6d"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de0cc64b-36bf-4c34-8dad-7ec66c9e2540",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T07:01:57.888780200Z",
     "start_time": "2024-06-24T07:01:57.838061500Z"
    }
   },
   "outputs": [],
   "source": [
    "from darts.models import RNNModel\n",
    "import pandas as pd\n",
    "\n",
    "class RNNHolder(Benchmark.BenchmarkModelHolder):\n",
    "    def __init__(self, name = \"RNN\", arguments_dict=None):\n",
    "        if arguments_dict is None:\n",
    "            arguments_dict = {'input_chunk_length': 1, 'pred_length': 1}\n",
    "        self.model = None\n",
    "        self.name = name\n",
    "        self.input_chunk_length = arguments_dict['input_chunk_length']\n",
    "        self.pred_length = arguments_dict['pred_length']\n",
    "        self.train_tmp = None\n",
    "        self.train_cov = None\n",
    "    \n",
    "    def instantiate(self, train_set: TimeSeries, test_set: TimeSeries, **kwargs):\n",
    "        self.model = RNNModel(    \n",
    "            model=\"RNN\",\n",
    "            input_chunk_length=self.input_chunk_length,\n",
    "            output_chunk_length=1,\n",
    "            n_epochs=20,\n",
    "        )\n",
    "    \n",
    "    def fit(self, training_set: TimeSeries, test_set: TimeSeries, target_column, multivariate= False):\n",
    "        train_target = training_set[target_column]\n",
    "        self.train_cov = training_set.drop_columns(target_column)\n",
    "        self.model.fit(train_target)#, future_covariates = self.train_cov)\n",
    "        \n",
    "    def predict(self, pred_length, test_set: TimeSeries, target_column, multivariate = False):\n",
    "        pred_length = len(test_set.time_index) - 1\n",
    "        target = test_set[target_column]\n",
    "        cov = pd.concat([self.train_cov.pd_dataframe(), test_set.drop_columns(target_column).pd_dataframe()])\n",
    "        cov = TimeSeries.from_pandas(cov)\n",
    "        return self.model.predict(pred_length, \n",
    "                    series = target, \n",
    "                    #past_covariates = cov, \n",
    "                    #future_covariates = cov, \n",
    "                    verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4a751a9-4688-4a31-b231-320166455795",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T07:01:58.355745600Z",
     "start_time": "2024-06-24T07:01:58.347640700Z"
    }
   },
   "outputs": [],
   "source": [
    "m3 = RNNHolder(name='RNN', arguments_dict = {'input_chunk_length': 10, 'pred_length': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e2cf8f-69e1-4988-a8d4-c70b06a29019",
   "metadata": {},
   "source": [
    "\n",
    "### Preparing datasets\n",
    "Datasets submitted to a Benchmark must be of type TimeSeries. Pre-wrapping them into a BenchmarkDataset allows to give them a name, give training and test sets, and declare if it's univariate or multivariate. A tuple of timeseries (train set, test set) can also be submitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a1eb452-f598-4e7c-9f7f-88a1185c3c6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T07:01:59.080728800Z",
     "start_time": "2024-06-24T07:01:58.986935500Z"
    }
   },
   "outputs": [],
   "source": [
    "from ontime.module.data.dataset import Dataset\n",
    "from darts.utils.model_selection import train_test_split\n",
    "\n",
    "d1 = Dataset.AirPassengersDataset.load() \n",
    "ausbeer = Dataset.AusBeerDataset.load()\n",
    "d2 = Benchmark.BenchmarkDataset(ausbeer, multivariate = False, name = \"AusBeerDataset\")\n",
    "heartrate = Dataset.HeartRateDataset.load()\n",
    "heartrate_train, heartrate_test = train_test_split(heartrate, test_size = 0.5)\n",
    "d3 = (heartrate_train, heartrate_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd484f03-399d-4e4e-9b7c-2462e6accbb9",
   "metadata": {},
   "source": [
    "### Preparing metrics\n",
    "Metrics must be wrapped in a Benchmark.BenchmarkMetric instance. Again, if the function can't be invoked as in BenchmarkMetric's implementation, a child class can be written and submitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bd6e05b-d86a-484a-bd28-7559b640c20f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T07:01:59.701881200Z",
     "start_time": "2024-06-24T07:01:59.693974700Z"
    }
   },
   "outputs": [],
   "source": [
    "import darts\n",
    "\n",
    "me1 = Benchmark.BenchmarkMetric(name=\"RMSE\", metric_function=darts.metrics.metrics.coefficient_of_variation)\n",
    "me2 = Benchmark.BenchmarkMetric(name=\"MAE\", metric_function=darts.metrics.metrics.mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ce9193-2bd1-4859-b5c5-17a48cb4e0fa",
   "metadata": {},
   "source": [
    "## Creating a Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b99abb03-c3ee-4e19-87a7-c86e1b418a6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T07:02:00.671042500Z",
     "start_time": "2024-06-24T07:02:00.650794500Z"
    }
   },
   "outputs": [],
   "source": [
    "benchmark = Benchmark(datasets = [d1, d2, d3], # datasets submitted as simple TimeSeries will be given a number as a name\n",
    "                      models = [m1, m2, m3], \n",
    "                      metrics = [me1, me2], \n",
    "                      train_proportion=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b7a83a-e878-4fbf-818a-3c70f73bcb05",
   "metadata": {},
   "source": [
    "Datasets, models and metrics can also be added after instanciation. This allows to name datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "005d3bae-1fdb-4edd-91ba-0df918fae5fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T07:02:01.526327100Z",
     "start_time": "2024-06-24T07:02:01.515552400Z"
    }
   },
   "outputs": [],
   "source": [
    "benchmark2 = Benchmark()\n",
    "benchmark2.add_model(m1)\n",
    "benchmark2.add_dataset(d1, name = \"AirPassengerDataset\")\n",
    "benchmark2.add_metric(me1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86ec250-db58-4c10-b4e3-14c2b23bcf70",
   "metadata": {},
   "source": [
    "Once the models and datasets have been added, the run() method will train instances of all the models on all the datasets individually and compute metrics. The verbose parameter will print the status and results of the process as it progresses, and the debug parameter will print error messages (warnings are printed anyways)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e96d8811-efd0-4cb0-bf7c-a03364e05911",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T07:02:58.799456800Z",
     "start_time": "2024-06-24T07:02:02.671394200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation...\n",
      "Evaluation for model ARIMA\n",
      "on dataset 0, column #Passengers \n",
      "training... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charlie/.local/lib/python3.10/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "/home/charlie/.local/lib/python3.10/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done, took 1.317589521408081\n",
      "testing... done, took 0.004683971405029297\n",
      "RMSE: Index(['#Passengers'], dtype='object', name='component') #Passengers\n",
      "3.6823375607771083\n",
      "MAE: Index(['#Passengers'], dtype='object', name='component') #Passengers\n",
      "13.397485829577487\n",
      "on dataset AusBeerDataset, column Y \n",
      "training... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charlie/.local/lib/python3.10/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done, took 1.8718085289001465\n",
      "testing... done, took 0.00490117073059082\n",
      "RMSE: Index(['Y'], dtype='object', name='component') Y\n",
      "4.350713610378453\n",
      "MAE: Index(['Y'], dtype='object', name='component') Y\n",
      "15.369339480209591\n",
      "on dataset 2, column Heart rate \n",
      "training... done, took 3.502897024154663\n",
      "testing... done, took 0.028519868850708008\n",
      "RMSE: Index(['Heart rate'], dtype='object', name='component') Heart rate\n",
      "6.606337568439427\n",
      "MAE: Index(['Heart rate'], dtype='object', name='component') Heart rate\n",
      "5.044218953626089\n",
      "Evaluation for model BATS\n",
      "on dataset 0, column #Passengers \n",
      "training... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charlie/.local/lib/python3.10/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done, took 8.070533275604248\n",
      "testing... done, took 0.0036497116088867188\n",
      "RMSE: Index(['#Passengers'], dtype='object', name='component') #Passengers\n",
      "8.321211346269285\n",
      "MAE: Index(['#Passengers'], dtype='object', name='component') #Passengers\n",
      "33.570078021466806\n",
      "on dataset AusBeerDataset, column Y \n",
      "training... done, took 13.329428911209106\n",
      "testing... done, took 0.0023772716522216797\n",
      "RMSE: Index(['Y'], dtype='object', name='component') Y\n",
      "4.378445630437863\n",
      "MAE: Index(['Y'], dtype='object', name='component') Y\n",
      "13.398303193058819\n",
      "on dataset 2, column Heart rate \n",
      "training... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "darts.models.forecasting.rnn_model WARNING ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.\n",
      "darts.models.forecasting.torch_forecasting_model INFO  Train dataset contains 104 samples.\n",
      "darts.models.forecasting.torch_forecasting_model INFO  Time series values are 64-bits; casting model to float64.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rnn           | RNN              | 700   \n",
      "4 | V             | Linear           | 26    \n",
      "---------------------------------------------------\n",
      "726       Trainable params\n",
      "0         Non-trainable params\n",
      "726       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done, took 17.23955535888672\n",
      "testing... done, took 0.002389192581176758\n",
      "RMSE: Index(['Heart rate'], dtype='object', name='component') Heart rate\n",
      "6.577731759671614\n",
      "MAE: Index(['Heart rate'], dtype='object', name='component') Heart rate\n",
      "4.963032869193333\n",
      "Evaluation for model RNN\n",
      "on dataset 0, column #Passengers \n",
      "training... "
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7765e6527154b329222b4d8289fd157"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "darts.models.forecasting.rnn_model WARNING ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.\n",
      "darts.models.forecasting.torch_forecasting_model INFO  Train dataset contains 165 samples.\n",
      "darts.models.forecasting.torch_forecasting_model INFO  Time series values are 64-bits; casting model to float64.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rnn           | RNN              | 700   \n",
      "4 | V             | Linear           | 26    \n",
      "---------------------------------------------------\n",
      "726       Trainable params\n",
      "0         Non-trainable params\n",
      "726       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done, took 1.2166600227355957\n",
      "testing... done, took 0.08661961555480957\n",
      "RMSE: Index(['#Passengers'], dtype='object', name='component') #Passengers\n",
      "nan\n",
      "MAE: Index(['#Passengers'], dtype='object', name='component') #Passengers\n",
      "nan\n",
      "on dataset AusBeerDataset, column Y \n",
      "training... "
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "561c723763b54d63a97865a47eb5d7f0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "darts.models.forecasting.rnn_model WARNING ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.\n",
      "darts.models.forecasting.torch_forecasting_model INFO  Train dataset contains 876 samples.\n",
      "darts.models.forecasting.torch_forecasting_model INFO  Time series values are 64-bits; casting model to float64.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rnn           | RNN              | 700   \n",
      "4 | V             | Linear           | 26    \n",
      "---------------------------------------------------\n",
      "726       Trainable params\n",
      "0         Non-trainable params\n",
      "726       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done, took 1.6621193885803223\n",
      "testing... done, took 0.08975815773010254\n",
      "RMSE: Index(['Y'], dtype='object', name='component') Y\n",
      "nan\n",
      "MAE: Index(['Y'], dtype='object', name='component') Y\n",
      "nan\n",
      "on dataset 2, column Heart rate \n",
      "training... "
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7b3faeea2ab4b83bd9fd2271d639485"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done, took 7.097806453704834\n",
      "testing... done, took 0.28192710876464844\n",
      "RMSE: Index(['Heart rate'], dtype='object', name='component') Heart rate\n",
      "nan\n",
      "MAE: Index(['Heart rate'], dtype='object', name='component') Heart rate\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "benchmark.run(verbose = True, debug = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4038313-7cf4-480d-8d3c-fd030e100da3",
   "metadata": {},
   "source": [
    "To view the results, you can call get_report() and print the returned value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35b9b732-bd80-426f-a8bb-134f06bf1a3b",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-24T07:04:00.885598500Z",
     "start_time": "2024-06-24T07:04:00.878375900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ARIMA:\n",
      "Supported univariate datasets: ✓\n",
      "Supported multivariate datasets: unknown\n",
      "Dataset 0, #Passengers:\n",
      "nb features: 1\n",
      "target column: #Passengers\n",
      "training set size: 128\n",
      "training time: 1.317589521408081\n",
      "test set size: 16\n",
      "testing time: 0.004683971405029297\n",
      "RMSE: 3.6823375607771083\n",
      "MAE: 13.397485829577487\n",
      "Dataset AusBeerDataset, Y:\n",
      "nb features: 1\n",
      "target column: Y\n",
      "training set size: 189\n",
      "training time: 1.8718085289001465\n",
      "test set size: 22\n",
      "testing time: 0.00490117073059082\n",
      "RMSE: 4.350713610378453\n",
      "MAE: 15.369339480209591\n",
      "Dataset 2, Heart rate:\n",
      "nb features: 1\n",
      "target column: Heart rate\n",
      "training set size: 900\n",
      "training time: 3.502897024154663\n",
      "test set size: 900\n",
      "testing time: 0.028519868850708008\n",
      "RMSE: 6.606337568439427\n",
      "MAE: 5.044218953626089\n",
      "\n",
      "\n",
      "Model BATS:\n",
      "Supported univariate datasets: ✓\n",
      "Supported multivariate datasets: unknown\n",
      "Dataset 0, #Passengers:\n",
      "nb features: 1\n",
      "target column: #Passengers\n",
      "training set size: 128\n",
      "training time: 8.070533275604248\n",
      "test set size: 16\n",
      "testing time: 0.0036497116088867188\n",
      "RMSE: 8.321211346269285\n",
      "MAE: 33.570078021466806\n",
      "Dataset AusBeerDataset, Y:\n",
      "nb features: 1\n",
      "target column: Y\n",
      "training set size: 189\n",
      "training time: 13.329428911209106\n",
      "test set size: 22\n",
      "testing time: 0.0023772716522216797\n",
      "RMSE: 4.378445630437863\n",
      "MAE: 13.398303193058819\n",
      "Dataset 2, Heart rate:\n",
      "nb features: 1\n",
      "target column: Heart rate\n",
      "training set size: 900\n",
      "training time: 17.23955535888672\n",
      "test set size: 900\n",
      "testing time: 0.002389192581176758\n",
      "RMSE: 6.577731759671614\n",
      "MAE: 4.963032869193333\n",
      "\n",
      "\n",
      "Model RNN:\n",
      "Supported univariate datasets: ✓\n",
      "Supported multivariate datasets: unknown\n",
      "Dataset 0, #Passengers:\n",
      "nb features: 1\n",
      "target column: #Passengers\n",
      "training set size: 128\n",
      "training time: 1.2166600227355957\n",
      "test set size: 16\n",
      "testing time: 0.08661961555480957\n",
      "RMSE: nan\n",
      "MAE: nan\n",
      "Dataset AusBeerDataset, Y:\n",
      "nb features: 1\n",
      "target column: Y\n",
      "training set size: 189\n",
      "training time: 1.6621193885803223\n",
      "test set size: 22\n",
      "testing time: 0.08975815773010254\n",
      "RMSE: nan\n",
      "MAE: nan\n",
      "Dataset 2, Heart rate:\n",
      "nb features: 1\n",
      "target column: Heart rate\n",
      "training set size: 900\n",
      "training time: 7.097806453704834\n",
      "test set size: 900\n",
      "testing time: 0.28192710876464844\n",
      "RMSE: nan\n",
      "MAE: nan\n"
     ]
    }
   ],
   "source": [
    "print(benchmark.get_report())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0852085-874e-4583-9f91-1efcb486fbcb",
   "metadata": {},
   "source": [
    "You can also get results by calling get_report_dataframes(). The results are then returned as a dictionary with the model names as keys and dataframes as values, where columns are measures (testing time, metrics, etc.) and index is the dataset names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "687a0b79-ff02-4bde-aff7-6d6ccd5e7d40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T07:04:03.237516900Z",
     "start_time": "2024-06-24T07:04:03.207950400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA:\n",
      "                nb features target column  training set size  training time  \\\n",
      "0                         1   #Passengers                128       1.317590   \n",
      "AusBeerDataset            1             Y                189       1.871809   \n",
      "2                         1    Heart rate                900       3.502897   \n",
      "\n",
      "                test set size  testing time  prediction      RMSE        MAE  \n",
      "0                          16      0.004684         NaN  3.682338  13.397486  \n",
      "AusBeerDataset             22      0.004901         NaN  4.350714  15.369339  \n",
      "2                         900      0.028520         NaN  6.606338   5.044219  \n",
      "--------------------------------------------------\n",
      "BATS:\n",
      "                nb features target column  training set size  training time  \\\n",
      "0                         1   #Passengers                128       8.070533   \n",
      "AusBeerDataset            1             Y                189      13.329429   \n",
      "2                         1    Heart rate                900      17.239555   \n",
      "\n",
      "                test set size  testing time      RMSE        MAE  \n",
      "0                          16      0.003650  8.321211  33.570078  \n",
      "AusBeerDataset             22      0.002377  4.378446  13.398303  \n",
      "2                         900      0.002389  6.577732   4.963033  \n",
      "--------------------------------------------------\n",
      "RNN:\n",
      "                nb features target column  training set size  training time  \\\n",
      "0                         1   #Passengers                128       1.216660   \n",
      "AusBeerDataset            1             Y                189       1.662119   \n",
      "2                         1    Heart rate                900       7.097806   \n",
      "\n",
      "                test set size  testing time  RMSE  MAE  \n",
      "0                          16      0.086620   NaN  NaN  \n",
      "AusBeerDataset             22      0.089758   NaN  NaN  \n",
      "2                         900      0.281927   NaN  NaN  \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dfs = benchmark.get_report_dataframes()\n",
    "for df in dfs.keys():\n",
    "    print(f'{df}:')\n",
    "    print(dfs[df])\n",
    "    print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a113a1a8-6988-4440-9afc-c4e9b5e6f898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
